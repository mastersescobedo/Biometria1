{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicialización y funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar realizamos las importaciones que vamos ha necesitar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from natsort import natsorted\n",
    "from sklearn import model_selection\n",
    "from tensorflow.contrib.keras import applications\n",
    "from tensorflow.contrib.keras import layers, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una variables globales que vamos a necesitar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = 'faces/faces/train'\n",
    "data_path = 'faces/faces'\n",
    "n_classes = 151"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordenamos las categorias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names_categories = natsorted(os.listdir(categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una función que devuelve los datos y sus correspondientes etquetas para la fase de train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_data(names_categories, data_path):\n",
    "    X = []\n",
    "    y = []\n",
    "    # Se listan las categorias\n",
    "    for i, c in enumerate(names_categories):\n",
    "        # Sobre cada categoria se buscan lso archivos que pertenecesn\n",
    "        for f in os.listdir(os.path.join(data_path, 'train', c)):\n",
    "            img_path = os.path.join(data_path, 'train', c, f)\n",
    "            img = image.load_img(img_path, target_size=(299, 299))\n",
    "            x = image.img_to_array(img)\n",
    "            # Se almacena la imagen como datos de entrada y al categoria como etiqueta\n",
    "            X += [x]\n",
    "            y += [i]\n",
    "\n",
    "    y = np.array(y)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una función que devuelve los datos y sus correspondientes etquetas para la fase de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_data(names_categories, data_path):\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    # se ordenan los datos de igual manera que las categorias\n",
    "    for f in natsorted(os.listdir(os.path.join(data_path, 'test'))):\n",
    "        # A partir del nombre de la imagen se toma la categoria y\n",
    "        # se le asigna el mismo numero que en los datos de train\n",
    "        img_path = os.path.join(data_path, 'test', f)\n",
    "        name_category = f.split('.')[0]\n",
    "        label = names_categories.index(name_category)\n",
    "        # Se almacena la etiqueta en el vector de etiquetas\n",
    "        y_test.append(label)\n",
    "        # Se habre la imagen y se guarda en el vector de muestras\n",
    "        img = image.load_img(img_path, target_size=(299, 299))\n",
    "        x_test = image.img_to_array(img)\n",
    "\n",
    "        X_test += [x_test]\n",
    "\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    return X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejecución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = get_train_data(names_categories, data_path)\n",
    "X_test, y_test = get_test_data(names_categories, data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se preprocesan los datos para la que se encuentren acordes a la red ya preentrenada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = applications.inception_v3.preprocess_input(np.array(X))\n",
    "X_test = applications.inception_v3.preprocess_input(np.array(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se carga la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model = applications.inception_v3.InceptionV3(input_shape=(299, 299, 3), weights='imagenet', include_top=False)\n",
    "# add a global spatial average pooling layer\n",
    "x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "# Add the prediction layer of size n_classes\n",
    "predictions = layers.Dense(n_classes, activation='softmax')(x)\n",
    "model = models.Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define que capas son entrenables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:249]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza la separacion entre los datos de train y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define un optimizador y se realiza la compilacion del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=None, decay=0.0)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define el aumentado de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# datagen_train = ImageDataGenerator(\n",
    "#                 featurewise_center=True,\n",
    "#                 featurewise_std_normalization=True,\n",
    "#                 rotation_range=20,\n",
    "#                 width_shift_range=0.2,\n",
    "#                 height_shift_range=0.2,\n",
    "#                 horizontal_flip=True\n",
    "#                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se entrena el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2173 samples, validate on 544 samples\n",
      "Epoch 1/20\n",
      "67s - loss: 2.1125 - acc: 0.6199 - val_loss: 0.6949 - val_acc: 0.8327\n",
      "Epoch 2/20\n",
      "64s - loss: 0.1172 - acc: 0.9775 - val_loss: 0.1108 - val_acc: 0.9651\n",
      "Epoch 3/20\n",
      "67s - loss: 0.0261 - acc: 0.9949 - val_loss: 0.1550 - val_acc: 0.9540\n",
      "Epoch 4/20\n",
      "65s - loss: 0.0256 - acc: 0.9954 - val_loss: 0.6959 - val_acc: 0.8309\n",
      "Epoch 5/20\n",
      "66s - loss: 0.0162 - acc: 0.9977 - val_loss: 0.0429 - val_acc: 0.9835\n",
      "Epoch 6/20\n",
      "65s - loss: 0.0096 - acc: 0.9972 - val_loss: 0.2927 - val_acc: 0.9301\n",
      "Epoch 7/20\n",
      "64s - loss: 0.0032 - acc: 0.9995 - val_loss: 0.0510 - val_acc: 0.9816\n",
      "Epoch 8/20\n",
      "65s - loss: 0.0033 - acc: 0.9991 - val_loss: 0.4878 - val_acc: 0.8768\n",
      "Epoch 9/20\n",
      "64s - loss: 2.4912e-04 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 0.9982\n",
      "Epoch 10/20\n",
      "63s - loss: 0.0102 - acc: 0.9972 - val_loss: 0.0125 - val_acc: 0.9982\n",
      "Epoch 11/20\n",
      "64s - loss: 0.0090 - acc: 0.9991 - val_loss: 0.1074 - val_acc: 0.9706\n",
      "Epoch 12/20\n",
      "64s - loss: 0.0017 - acc: 0.9991 - val_loss: 0.3815 - val_acc: 0.9228\n",
      "Epoch 13/20\n",
      "64s - loss: 7.6197e-04 - acc: 1.0000 - val_loss: 0.0583 - val_acc: 0.9779\n",
      "Epoch 14/20\n",
      "66s - loss: 0.0048 - acc: 0.9995 - val_loss: 0.1735 - val_acc: 0.9485\n",
      "Epoch 15/20\n",
      "64s - loss: 0.0011 - acc: 0.9995 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "64s - loss: 0.0036 - acc: 0.9991 - val_loss: 0.0104 - val_acc: 0.9982\n",
      "Epoch 17/20\n",
      "64s - loss: 6.2521e-04 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 0.9982\n",
      "Epoch 18/20\n",
      "67s - loss: 0.0025 - acc: 0.9991 - val_loss: 0.1460 - val_acc: 0.9522\n",
      "Epoch 19/20\n",
      "64s - loss: 3.2371e-05 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 0.9982\n",
      "Epoch 20/20\n",
      "62s - loss: 1.1495e-04 - acc: 1.0000 - val_loss: 0.0139 - val_acc: 0.9926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.keras.python.keras.callbacks.History at 0x7fe038726c50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train, y=y_train, batch_size=20, epochs=20, validation_data=(x_val, y_val), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se evaluan los datos de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 7s     \n",
      "[0.048624822499236733, 0.98996655618067964]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X_test, y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
